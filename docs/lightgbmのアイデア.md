## 1. ヒストグラムベースの分割探索

### アイデア
連続値特徴量をあらかじめビン（bin）に分割して離散化し、分割点探索をビン単位で行うことで、ソートベースの探索に比べて計算量とメモリ使用量を低減する。

### 手順
1.  **ビン分割**
    *   各特徴量の取る値域を固定数（例：255）に等間隔または頻度等分で区切り、各サンプルの値を対応するビン番号にマッピングする。
2.  **ヒストグラム構築**
    *   ノードごとに、当該ノードに属するサンプルを走査し、各特徴・各ビンにおける勾配（およびヒストグラム内でのサンプル数）を累積する。
    *   このステップの計算量は O(データ数 × 特徴数) となる。
3.  **分割点探索**
    *   各ビンを候補として、ビン単位で左右ノードへの分割後の勾配和を利用して情報利得（Gain）を計算し、最適ビンを選択する。
    *   候補数は「ビン数 × 特徴数」であり、ビン数は通常データ数に比べて小さいため効率的。

### 効果
*   **計算速度の向上**
    *   ソートベースの O(データ数 × log(データ数) × 特徴数) に対し、ヒストグラム方式は O(データ数 × 特徴数 + ビン数 × 特徴数) となり、特にデータ数増加時に高速化が顕著。
*   **メモリ効率の改善**
    *   元の連続値をビン番号（小さな整数）で管理するため、特徴量をビン化した後はメモリ使用量が減少し、巨大データでも扱いやすくなる。

---

## 2. Gradient-based One-Side Sampling (GOSS)

### アイデア
GBDT において、勾配（＝残差）の絶対値が大きいサンプルほどモデルが学習していない部分を多く含むとみなし、そのようなサンプルを高い確率で保持し、勾配が小さいサンプルをサンプリングして数を削減することで、分割点探索の計算量を削減しながらも精度を維持する。
### 手順
1.  **勾配絶対値によるソート**
    *   各サンプル $i$ について現在のモデルでの負の勾配 $g_i$ を計算し、その絶対値 $|g_i|$ の降順に並べる。
2.  **大勾配サンプルの選択 (集合 A)**
    *   上位 $a\%$（例：10％）のサンプル集合をそのまま保持し、これを集合 A とする。
3.  **小勾配サンプルのランダム抽出 (集合 B)**
    *   残る下位 $(1 - a)\%$ のサンプル集合から、さらにランダムに $b\%$（例：10％）を抽出し、これを集合 B とする。
4.  **勾配補正**
    *   情報利得計算時に、集合 B の各サンプルに重み $\frac{1 - a}{b}$ を掛けて補正し、サンプリングバイアスを打ち消す。
5.  **ヒストグラム構築・分割探索**
    *   ノード分割のヒストグラム構築や情報利得計算は、集合 $A \cup B$ のサンプルのみで行う。ただし、B の勾配和には補正済みの重みを反映させる。

### 効果
*   **計算量削減**
    *   サンプル数を $(a + b)$ 倍に削減するため、ヒストグラム構築や分割探索にかかる時間が大幅に短縮される。
*   **精度維持**
    *   勾配が大きいサンプルを全量保持し、残りも確率的に代表サンプルを残すため、近似的に真の情報利得を計算でき、高い精度を保つ。
*   **理論的保証**
    *   論文内の誤差解析により、分割点ごとの情報利得誤差が大きなサンプル数下で急速に小さくなることが示されており、実験的にも GOSS は従来のランダムサンプリングよりも優れた精度-効率トレードオフを実現している。

---

## 3. Exclusive Feature Bundling (EFB)

### アイデア
高次元かつ疎（sparse）なデータにおいて、ほとんど同時に非ゼロとならない（排他的な）複数の特徴を 1 つの「バンドル」にまとめて扱うことで、ヒストグラム構築時の特徴数を削減し、計算コストとメモリ使用量を削減する。

### 手順
1.  **排他性グラフの構築**
    *   各特徴をグラフの頂点とみなし、2 つの特徴が少なくとも 1 インスタンスで同時に非ゼロである場合に辺を張る。
    *   このグラフにおける「頂点彩色問題」を解くように、排他的な特徴同士を同じ色（バンドル）にまとめたい。
2.  **グラフ彩色（貪欲近似）**
    *   NP–hard 問題のため、貪欲法による近似アルゴリズムを用いる（論文 Algorithm 3）。
    *   各頂点（特徴）を、「非ゼロ数／隣接辺数」などを基に優先度付けし、高優先度順に既存バンドルに追加可能かを判定。
    *   もし既存のバンドル内で許容される最大衝突率 γ 以下であれば追加し、それ以外は新たにバンドルを作成する。
3.  **バンドル単位でのビン再割り当て**
    *   バンドル内の各特徴 $f_j$ が持つ最大ビン数をそれぞれ $b_j$ とすると、バンドル全体のビン数は $\sum_j b_j$ となる。
    *   サンプルの元のビン値が $v_j$ であれば、新しいバンドル上のビン値を「 $v_j + \sum_{t < j} b_t$ 」と割り当てる（論文 Algorithm 4）。
    *   これにより、バンドルを単一特徴のように扱ってヒストグラムを構築できる。

### 効果
*   **特徴次元数の大幅削減**
    *   高次元かつ疎なデータでは、実質的に同時に非ゼロを取らない特徴が多数存在するため、バンドル数は元の特徴数に比べて大幅に少なくなる。
*   **ヒストグラム構築コストの削減**
    *   ヒストグラム構築時に扱う特徴数が減るため、O(データ数×バンドル数) となり、処理時間が数倍～十数倍高速化される。
*   **メモリ使用量の削減**
    *   バンドル数の減少に応じて、ビン情報の保存領域や中間状態のメモリが軽量化される。
*   **精度への影響が小さい**
    *   実験上、許容率 γ をある程度緩和しても、モデル精度（AUC や NDCG）には有意な悪影響が観察されていない。

---

## 4. Leaf-wise（葉優先）成長戦略

### アイデア
GBDT のツリー構築において、従来の「深さ（レベル）単位で均等に分割を行う」方法ではなく、「最も誤差減少が大きい葉ノードを優先して分割する」ことで、同じ学習回数や同じ最大深度でも、より効率的に学習誤差を減少させる。

### 手順
1.  **全葉候補の情報利得計算**
    *   現在の木において、分割可能な各葉ノードごとに「その葉を分割したときの情報利得（Gain）」を計算する。
2.  **最大 Gain の葉を選択**
    *   情報利得が最大となる葉ノードを特定し、そのノードのみを分割して左右子を生成する。
3.  **次のノード探索**
    *   新たに生成された子ノードや既存の未分割葉も含め、再度すべての葉候補を評価して、最大 Gain のものを次に分割する。
4.  **ストッピング条件**
    *   ツリーの成長は、所定の木の深さ (max_depth)、葉の最小サンプル数 (min_data_in_leaf)、あるいは学習回数 (num_leaves) に達したら停止する。

### 効果
*   **学習効率の向上**
    *   同一のリソース（学習回数や深さ）であっても、より早い段階で誤差減少が大きい分割を行うため、収束が速い。
*   **モデルサイズの削減**
    *   必要性の低い分割を行わないため、深さは不均一になるが、少ないノード数で高い精度を実現でき、メモリ使用量も抑制される。
*   **過学習への注意**
    *   一部の分割が極端に深くなる傾向があるため、過学習しやすい。したがって、max_depth や min_data_in_leaf といったパラメータで制御する必要がある。

---

## 5. スパース最適化（Sparse Optimization）

### アイデア
入力データにおけるゼロ値（特に疎な特徴のゼロ）を効率的に飛ばしてヒストグラムを構築し、余計なメモリアクセスや計算を削減する。EFB と組み合わせることで、バンドル内の非ゼロ位置を効率的に処理する。

### 手順
1.  **非ゼロ要素のインデックス記録**
    *   学習開始時に、すべての特徴（またはバンドル単位）の「非ゼロを取るサンプルインデックス」のリストを構築しておく。
2.  **ヒストグラム構築時のスキッピング**
    *   ノードごとに属するサンプル集合を持つが、ヒストグラムを作る際には「非ゼロ要素リスト」に基づき、ゼロのものはスキップして計算する。
    *   具体的には、ヒストグラム更新ループでゼロバケットを飛ばし、「非ゼロだけを訪問」して勾配情報を加算する。
3.  **EFB と組み合わせた最適化**
    *   バンドル単位で「このバンドル内で非ゼロを取るサンプル／ビン値」をまとめて管理し、バンドルごとにヒストグラムを構築するときにも同様にスパースアクセスを適用する。

### 効果
*   **不要なメモリアクセス削減**
    *   多くの疎なデータでは、ほとんどのエントリがゼロであるため、それらをスキップできることでメモリアクセス回数が大幅に減少し、キャッシュヒット率が向上する。
*   **計算コストの削減**
    *   ヒストグラム更新時にゼロバケットを扱わないため、ビン更新や勾配累積の回数が減り、全体の計算量も低減される。
*   **EFB との相乗効果**
    *   排他的バンドルによって疎度がさらに高まった特徴群においても、バンドルごとのスパース情報を用いることで、バンドル単位でのビン更新も効率的に行える。

---

## 6. マルチスレッド並列化

### アイデア
ヒストグラム構築や情報利得計算は、特徴量ごとに独立して計算できる部分が多く、複数スレッドで並列化することで CPU 利用率を最大化し、高速化を図る。

### 手順
1.  **スレッドプールの生成**
    *   学習開始時に利用するスレッド数（例：16）を指定し、スレッドプールを用意する。
2.  **特徴単位のタスク分割**
    *   ヒストグラム構築フェーズ：特徴ごとに「その特徴に対するヒストグラム更新タスク」を生成し、スレッドプールに割り当てる。
    *   情報利得計算フェーズ：ビンごとの左右勾配和は特徴ごとに独立して算出可能なため、同様に複数スレッドで処理する。
3.  **同期と集約**
    *   各スレッドが計算した部分ヒストグラムや部分情報利得をメインスレッドで集約し、ノードの最適分割を決定する。
4.  **動的負荷分散**
    *   特徴によって非ゼロ率やビン数が異なるため、負荷差が激しくなりやすい。LightGBM では、タスクキューを用いてスレッド間で動的にタスクを割り振り、負荷を均等化する。

### 効果
*   **学習速度の向上**
    *   マルチコア CPU をフル活用することで、ヒストグラム構築や分割探索のボトルネックを並列処理し、単純にシングルスレッド時と比較して数倍の高速化を実現する。
*   **スループットの改善**
    *   大規模データセット（数千万行など）の場合でも、多スレッド化によりメモリアクセスや計算が並列に進むため、バッチ学習時間が大幅に短縮される。
*   **スケーラビリティ**
    *   スレッド数を増加させることで、より大きなデータセットや特徴次元でも効率的に学習可能となり、サーバリソースを柔軟に活用できる。